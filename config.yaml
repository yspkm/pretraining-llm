config:
  max_len_seq: 1024 
  num_layers: 32
  dim_model: 2304 
  dim_hidden: 9216 
  num_heads: 36
  prob_dropout: 0.50
  batch_size: 20 
  val_interval: 1000 
  total_steps: 550000
  # 4409721
  val_steps: 50 
  grad_accum_steps: 25
  lr_peak: 0.000025 # 휴리스틱
  weight_decay: 0.01
  warmup_steps: 2000
  balance: [11, 11, 11, 1]
  devices: ["cuda:0", "cuda:1", "cuda:2", "cuda:3"]
wandb:
  project_name: "AutoLLaMA"
  model_name: "llama"
