config:
  max_len_seq: 1024 
  num_layers: 32
  dim_model: 2048 
  dim_hidden: 6144 
  num_heads: 32
  prob_dropout: 0.50
  batch_size: 20 
  val_interval: 1024 
  total_steps: 550000
  # 4409721 / 8
  val_steps: 50 
  grad_accum_steps: 25
  lr_peak: 0.00005
  weight_decay: 0.01
  warmup_steps: 2000 
  balance: [11, 11, 11, 1]
  devices: ["cuda:0", "cuda:1", "cuda:2", "cuda:3"]
wandb:
  project_name: "AutoLLaMA"
  model_name: "llama"